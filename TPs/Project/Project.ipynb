{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8ed8e38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kaggle in /usr/lib/python3.6/site-packages (1.5.12)\n",
      "Requirement already satisfied: urllib3 in /usr/lib/python3/dist-packages (from kaggle) (1.22)\n",
      "Requirement already satisfied: six>=1.10 in /mnt/c/Users/V3D/Desktop/COURS/MachineLearningProject/env/lib/python3.6/site-packages (from kaggle) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil in /mnt/c/Users/V3D/Desktop/COURS/MachineLearningProject/env/lib/python3.6/site-packages (from kaggle) (2.8.2)\n",
      "Requirement already satisfied: certifi in /usr/lib/python3/dist-packages (from kaggle) (2018.1.18)\n",
      "Requirement already satisfied: python-slugify in /usr/lib/python3.6/site-packages (from kaggle) (6.1.1)\n",
      "Requirement already satisfied: requests in /usr/lib/python3/dist-packages (from kaggle) (2.18.4)\n",
      "Requirement already satisfied: tqdm in /usr/lib/python3.6/site-packages (from kaggle) (4.63.0)\n",
      "Requirement already satisfied: text-unidecode>=1.3 in /usr/lib/python3.6/site-packages (from python-slugify->kaggle) (1.3)\n",
      "Requirement already satisfied: importlib-resources in /usr/lib/python3.6/site-packages (from tqdm->kaggle) (5.4.0)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /usr/lib/python3.6/site-packages (from importlib-resources->tqdm->kaggle) (3.6.0)\n",
      "Requirement already satisfied: Pillow in /usr/lib/python3.6/site-packages (8.4.0)\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'webcolors'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-be1aeade498c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mPIL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExifTags\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTAGS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspatial\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mKDTree\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m from webcolors import (\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0mCSS3_HEX_TO_NAMES\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mhex_to_rgb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'webcolors'"
     ]
    }
   ],
   "source": [
    "# Data Collection\n",
    "\n",
    "!pip install kaggle --upgrade\n",
    "!pip3 install Pillow\n",
    "\n",
    "import kaggle\n",
    "import os\n",
    "import json\n",
    "import random\n",
    "from datetime import datetime\n",
    "from PIL import Image, ImageStat\n",
    "from PIL.ExifTags import TAGS\n",
    "from scipy.spatial import KDTree\n",
    "from webcolors import (\n",
    "    CSS3_HEX_TO_NAMES,\n",
    "    hex_to_rgb,\n",
    ")\n",
    "\n",
    "def get_predominant_colors(image_file, numcolors=3, resize=150, output = []):\n",
    "    # Resize image to speed up processing\n",
    "    img = Image.open(image_file)\n",
    "    img = img.copy()\n",
    "    img.thumbnail((resize, resize))\n",
    " \n",
    "    # Reduce to palette\n",
    "    paletted = img.convert('P', palette=Image.ADAPTIVE, colors=numcolors)\n",
    " \n",
    "    # Find dominant colors\n",
    "    palette = paletted.getpalette()\n",
    "    color_counts = sorted(paletted.getcolors(), reverse=True)\n",
    "    colors = list()\n",
    "    for i in range(numcolors):\n",
    "        palette_index = color_counts[i][1]\n",
    "        dominant_color = palette[palette_index*3:palette_index*3+3]\n",
    "        colors.append(tuple(dominant_color))\n",
    "    return colors\n",
    "\n",
    "def convert_rgb_to_names(rgb_tuple):\n",
    "    \n",
    "    # a dictionary of all the hex and their respective names in css3\n",
    "    css3_db = CSS3_HEX_TO_NAMES\n",
    "    names = []\n",
    "    rgb_values = []    \n",
    "    for color_hex, color_name in css3_db.items():\n",
    "        names.append(color_name)\n",
    "        rgb_values.append(hex_to_rgb(color_hex))\n",
    "    \n",
    "    kdt_db = KDTree(rgb_values)    \n",
    "    distance, index = kdt_db.query(rgb_tuple)\n",
    "    return int(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe5ceff",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## You have to collect and download a set of images. You have the following tasks to program, automating the process as much as possible:\n",
    "### 1. Create a folder called images.\n",
    "\n",
    "!mkdir -p ./images\n",
    "!mkdir -p ./metadata\n",
    "\n",
    "### 2. Download open-licensed images to the folder images (minimum 100 images).\n",
    "\n",
    "kaggle.api.authenticate()\n",
    "kaggle.api.dataset_download_files('nielspace/pexels-mountain-images', path='./images', unzip=True)    \n",
    "    \n",
    "### 3. Save metadata of every image like image size, image format (.jpeg, .png, etc.), image orientation (landscape, portrait, square, etc.), creation date, camera model, etc. in one or more JSON files. You can make use of the Exif information present in the image files.\n",
    "\n",
    "directory = './images/Mountain'\n",
    "metadata = {}\n",
    "orientation = \"\"\n",
    "images_data =[]\n",
    "for filename in os.listdir(directory) :\n",
    "    f = os.path.join(directory, filename)\n",
    "    if os.path.isfile(f):\n",
    "        image_data = {}\n",
    "        path, file_extension = os.path.splitext(f)\n",
    "        time_creation = os.path.getmtime(f)\n",
    "        im = Image.open(f)\n",
    "        size = im.size\n",
    "        colors = {}\n",
    "        predominant_colors = get_predominant_colors(directory + \"/\" + filename)\n",
    "        colors[\"predominant_colors\"] = []\n",
    "        for predominant_color in predominant_colors:\n",
    "            colors[\"predominant_colors\"].append(convert_rgb_to_names(predominant_color))\n",
    "        for idx,val in enumerate([\"red\",\"green\",\"blue\"]):\n",
    "            colors[val] = Image.Image.getextrema(im)[idx]\n",
    "            colors[val] = colors[val] + (ImageStat.Stat(im).median[idx],)\n",
    "        if size[0]>size[1] :\n",
    "            orientation = \"landscape\"\n",
    "        elif size[0] == size[1] :\n",
    "            orientation = \"square\"\n",
    "        else :\n",
    "            orientation = \"portrait\"\n",
    "        metadata[filename] = {\n",
    "            \"file_extension\": file_extension,\n",
    "            \"creation_date\": datetime.fromtimestamp(time_creation/1000.0).strftime(\"%m/%d/%Y, %H:%M:%S\"),\n",
    "            \"size\": {\n",
    "                \"width\":size[0],\n",
    "                \"height\":size[1]\n",
    "            },\n",
    "            \"orientation\": orientation,\n",
    "            \"colors\": {\n",
    "                \"predominant_colors\":{\n",
    "                    \"first_color\":colors[\"predominant_colors\"][0],\n",
    "                    \"second_color\":colors[\"predominant_colors\"][1],\n",
    "                    \"third_color\":colors[\"predominant_colors\"][2]\n",
    "                },\n",
    "                \"red\": {\n",
    "                    \"minimum\":colors[\"red\"][0],\n",
    "                    \"maximum\":colors[\"red\"][1],\n",
    "                    \"median\":colors[\"red\"][2]\n",
    "                },\n",
    "                \"green\": {\n",
    "                    \"minimum\":colors[\"green\"][0],\n",
    "                    \"maximum\":colors[\"green\"][1],\n",
    "                    \"median\":colors[\"green\"][2]\n",
    "                },\n",
    "                \"blue\": {\n",
    "                    \"minimum\":colors[\"blue\"][0],\n",
    "                    \"maximum\":colors[\"blue\"][1],\n",
    "                    \"median\":colors[\"blue\"][2]\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "        print(metadata[filename])\n",
    "\n",
    "\n",
    "with open(\"./metadata/metadata.json\", \"w\") as outfile:\n",
    "    json.dump(metadata, outfile, indent=4)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f171704",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Labeling and Annotation\n",
    "\n",
    "directory = './images/Mountain'\n",
    "data_path = \"./metadata/metadata.json\"\n",
    "\n",
    "\n",
    "if os.path.isfile(data_path):\n",
    "    with open(data_path) as target:\n",
    "        json_data = json.load(target)\n",
    "        \n",
    "for filename in os.listdir(directory) :\n",
    "    f = os.path.join(directory, filename)\n",
    "    if os.path.isfile(f):\n",
    "        tags = {}\n",
    "        tags[\"like\"] = random.randint(0,100)\n",
    "        tags[\"hashtag\"] = \"moutain\"\n",
    "        json_data[filename][\"tags\"] = tags\n",
    "        \n",
    "with open(\"./metadata/metadata.json\", \"w\") as outfile:\n",
    "    json.dump(json_data, outfile, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46baa84a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "# Data Analyses\n",
    "\n",
    "numb_users = 1\n",
    "directory = './images/Mountain'\n",
    "data_path = \"./metadata/metadata.json\"\n",
    "rand = 0\n",
    "\n",
    "# Metadata for each file\n",
    "if os.path.isfile(data_path):\n",
    "    with open(data_path) as target:\n",
    "        json_data = json.load(target)\n",
    "\n",
    "# Creating data for each user\n",
    "json_data_users = {}        \n",
    "for i in range (0, numb_users):\n",
    "    images_per_users_rand = []\n",
    "    images_per_users_orientation = []\n",
    "    images_per_users_colors = []\n",
    "    tags_per_users = []\n",
    "    rand = random.randint(1, 4)\n",
    "    if rand == 1:\n",
    "        tags_per_users.append([\"like\", \"colors\"])\n",
    "    elif rand == 2:\n",
    "        tags_per_users.append(\"colors\")\n",
    "    elif rand == 3:\n",
    "        tags_per_users.append([\"hashtag\", \"colors\"])\n",
    "    else:\n",
    "        tags_per_users.append([\"like, hashtag\", \"colors\"])\n",
    "    for filename in os.listdir(directory) :\n",
    "        f = os.path.join(directory, filename)\n",
    "        if os.path.isfile(f):\n",
    "            ## First solution to get images a user liked\n",
    "            rand = random.randint(1, 5)\n",
    "            if rand == 1 :\n",
    "                images_per_users_rand.append(filename)\n",
    "            ## Second solution to get images u user liked\n",
    "            if (json_data[filename][\"orientation\"] == \"landscape\"):\n",
    "                images_per_users_orientation.append(filename)\n",
    "            ## Third solution to get images u user liked\n",
    "            if (json_data[filename][\"colors\"][0][0] >= 155):\n",
    "                images_per_users_colors.append(filename)\n",
    "    json_data_users[i] = {\n",
    "        \"images_rand\": images_per_users_rand,\n",
    "        \"images_orientation\": images_per_users_orientation,\n",
    "        \"images_colors\": images_per_users_colors,\n",
    "        \"tags\": tags_per_users\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ffd47215",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'accuracy_score' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-5f8c3f87fe8b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0mresult_all_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_result_dataframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson_data_users\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"images_orientation\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mle3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_all_images\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_all_images\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprediction_orientation_dtc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;31m# une image => deux info : l'étiquette et un vecteur ac les infos de l'image cette tchoin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'accuracy_score' is not defined"
     ]
    }
   ],
   "source": [
    "# Creating dataframes to predict what the user might like\n",
    "data = []\n",
    "result_rand = []\n",
    "result_orientation = []\n",
    "result_colors = []\n",
    "json_data_learning = dict(list(json_data.items())[:len(json_data)//3])\n",
    "\n",
    "def get_result_dataframe(json_data, json_data_users, key):\n",
    "    result = []\n",
    "    for i in json_data:\n",
    "        if i in json_data_users[0][key]:\n",
    "            result.append('Favorite')\n",
    "        else:\n",
    "            result.append('NotFavorite')\n",
    "    return result\n",
    "        \n",
    "result_rand = get_result_dataframe(json_data_learning, json_data_users, \"images_rand\")\n",
    "result_orientation = get_result_dataframe(json_data_learning, json_data_users, \"images_orientation\")\n",
    "result_colors = get_result_dataframe(json_data_learning, json_data_users, \"images_colors\")\n",
    "\n",
    "for i in json_data_learning:        \n",
    "    data.append([json_data_learning[i][\"colors\"][0][0],\n",
    "              json_data_learning[i][\"colors\"][0][1],\n",
    "              json_data_learning[i][\"colors\"][0][2],\n",
    "              json_data_learning[i][\"orientation\"], \n",
    "              json_data_learning[i][\"size\"][0],\n",
    "              json_data_learning[i][\"size\"][1]\n",
    "             ])\n",
    "\n",
    "dataframe = pd.DataFrame(data, columns=['Red', 'Green', 'Blue', 'Orientation', 'Width', 'Height'])\n",
    "resultframe_rand = pd.DataFrame(result_rand, columns=['Liked'])\n",
    "resultframe_orientation = pd.DataFrame(result_orientation, columns=['Liked'])\n",
    "resultframe_colors = pd.DataFrame(result_colors, columns=['Liked'])\n",
    "\n",
    "#generating numerical labels\n",
    "le1 = LabelEncoder()\n",
    "dataframe['Orientation'] = le1.fit_transform(dataframe['Orientation'])\n",
    "\n",
    "le2 = LabelEncoder()\n",
    "resultframe_rand['Liked'] = le2.fit_transform(resultframe_rand['Liked'])\n",
    "\n",
    "le3 = LabelEncoder()\n",
    "resultframe_orientation['Liked'] = le3.fit_transform(resultframe_orientation['Liked'])\n",
    "\n",
    "le4 = LabelEncoder()\n",
    "resultframe_colors['Liked'] = le4.fit_transform(resultframe_colors['Liked'])\n",
    "\n",
    "# DTC\n",
    "dtc_rand = tree.DecisionTreeClassifier()\n",
    "dtc_rand = dtc_rand.fit(dataframe, resultframe_rand)\n",
    "\n",
    "dtc_orientation = tree.DecisionTreeClassifier()\n",
    "dtc_orientation = dtc_orientation.fit(dataframe, resultframe_orientation)\n",
    "\n",
    "dtc_colors = tree.DecisionTreeClassifier()\n",
    "dtc_colors = dtc_colors.fit(dataframe, resultframe_colors)\n",
    "\n",
    "# RTC\n",
    "rfc_rand = RandomForestClassifier(n_estimators=10, max_depth=2, random_state=0)\n",
    "rfc_rand = rfc_rand.fit(dataframe, resultframe_rand.values.ravel())\n",
    "\n",
    "rfc_orientation = RandomForestClassifier(n_estimators=10, max_depth=2, random_state=0)\n",
    "rfc_orientation = rfc_orientation.fit(dataframe, resultframe_orientation.values.ravel())\n",
    "\n",
    "rfc_colors = RandomForestClassifier(n_estimators=10, max_depth=2, random_state=0)\n",
    "rfc_colors = rfc_colors.fit(dataframe, resultframe_colors.values.ravel())\n",
    "\n",
    "dataframe_prediction = []\n",
    "json_data_predicting = dict(list(json_data.items())[len(json_data)*2//3:])\n",
    "for j in json_data_predicting:\n",
    "    dataframe_prediction.append([json_data_predicting[j][\"colors\"][0][0],\n",
    "              json_data_predicting[j][\"colors\"][0][1],\n",
    "              json_data_predicting[j][\"colors\"][0][2],\n",
    "              le1.transform([json_data_predicting[j][\"orientation\"]])[0], \n",
    "              json_data_predicting[j][\"size\"][0],\n",
    "              json_data_predicting[j][\"size\"][1]\n",
    "             ])\n",
    "    \n",
    "def get_prediction(method_object, label_encoder, dataframe_prediction):\n",
    "    prediction = method_object.predict(dataframe_prediction) \n",
    "    return prediction\n",
    "\n",
    "\n",
    "prediction_rand_dtc = get_prediction(dtc_rand, le1, dataframe_prediction)\n",
    "prediction_orientation_dtc = get_prediction(dtc_orientation, le1, dataframe_prediction)\n",
    "prediction_colors_dtc = get_prediction(dtc_colors, le1, dataframe_prediction)\n",
    "\n",
    "prediction_rand_rfc = get_prediction(rfc_rand, le1, dataframe_prediction)\n",
    "prediction_orientation_rfc = get_prediction(rfc_orientation, le1, dataframe_prediction)\n",
    "prediction_colors_rfc = get_prediction(rfc_colors, le1, dataframe_prediction)\n",
    "  \n",
    "\n",
    "result_all_images = get_result_dataframe(json_data, json_data_users, \"images_orientation\")\n",
    "\n",
    "accuracy_score(le3.transform(result_all_images[len(result_all_images)*2//3:]), prediction_orientation_dtc)\n",
    "\n",
    "# une image => deux info : l'étiquette et un vecteur ac les infos de l'image cette tchoin\n",
    "# étiquette 0 (aime pas) ou 1 (aime)\n",
    "# find test split pr sklearn ça découpe les dataset automatiquement\n",
    "# skleanr accuracy score pour ce que j'ai fait au desssus mais en mieux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c23714",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
